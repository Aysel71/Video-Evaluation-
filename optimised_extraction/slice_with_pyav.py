import os
import shutil
import av
import numpy as np
import pysubs2
import json
from PIL import Image
import torch
from torchvision.transforms import ToTensor

def get_seq_frames(total_num_frames, step=16):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–∂–¥—ã–π step-–π –∫–∞–¥—Ä –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–≥–æ (–∏–Ω–¥–µ–∫—Å—ã: 0, step, 2*step, ...)
    –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç –∫–æ–Ω—Ü–∞ –≤–∏–¥–µ–æ.
    """
    selected_frames = list(range(0, total_num_frames, step))
    return selected_frames

def prepare_output_dirs(base_output_path):
    if os.path.exists(base_output_path):
        shutil.rmtree(base_output_path)
    os.makedirs(os.path.join(base_output_path, "frames"), exist_ok=True)

def slice_frames_pyav(video_path, srt_path, step=16, output_root="output"):
    video_id = os.path.splitext(os.path.basename(video_path))[0]
    output_path = os.path.join(output_root, video_id)
    frames_dir = os.path.join(output_path, "frames")
    print(f"\nüîç Processing video: {video_id}")
    prepare_output_dirs(output_path)
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å PyAV
    try:
        container = av.open(video_path)
        video_stream = container.streams.video[0]
        total_frames = int(video_stream.frames)
        fps = float(video_stream.average_rate)
        
        print(f"üìä –í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ: {total_frames}, FPS: {fps}")
        print(f"üîÑ –ò–∑–≤–ª–µ–∫–∞—é –∫–∞–∂–¥—ã–π {step}-–π –∫–∞–¥—Ä")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∫–∞–¥—Ä–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω—ã–º —à–∞–≥–æ–º
        selected_ids = get_seq_frames(total_frames, step)
        print(f"üéûÔ∏è –ë—É–¥–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(selected_ids)} –∫–∞–¥—Ä–æ–≤")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã
        subs = pysubs2.load(srt_path, encoding="utf-8") if srt_path and os.path.exists(srt_path) else []
        subtitles = []
        json_output = {
            "video_id": video_id,
            "frames": []
        }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
        for i, frame_idx in enumerate(selected_ids):
            print(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ {i+1}/{len(selected_ids)} (–∏–Ω–¥–µ–∫—Å {frame_idx})", end="\r")
            
            # –£—Å–∫–æ—Ä–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –ø–æ –≤–∏–¥–µ–æ
            container.seek(frame_idx, stream=video_stream)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä
            for frame in container.decode(video=0):
                # –ü–æ–ª—É—á–∞–µ–º numpy –º–∞—Å—Å–∏–≤
                img_array = frame.to_ndarray(format='rgb24')
                
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                
                # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É
                time_seconds = frame_idx / fps
                minutes = int(time_seconds // 60)
                seconds = int(time_seconds % 60)
                timestamp = f"{minutes:02d}:{seconds:02d}"
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                frame_name = f"{video_id}_frame_{timestamp}.jpg"
                frame_path = os.path.join(frames_dir, frame_name)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img = Image.fromarray(img_array)
                img.save(frame_path, quality=95)
                
                # –ù–∞–π–¥—ë–º —Å—É–±—Ç–∏—Ç—Ä
                cur_time_ms = int(time_seconds * 1000)
                matched_sub = ""
                for sub in subs:
                    if sub.start <= cur_time_ms <= sub.end:
                        matched_sub = sub.text.replace("\\N", " ").strip()
                        break
                subtitles.append(matched_sub)
                
                json_output["frames"].append({
                    "frame": frame_name,
                    "timestamp": timestamp,
                    "subtitle": matched_sub
                })
                
                break  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä –∏–∑ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
        
        print(f"\n‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º subtitles.txt
        with open(os.path.join(output_path, "subtitles.txt"), "w", encoding="utf-8") as f:
            f.write("\n".join(subtitles))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –µ–¥–∏–Ω—ã–π JSON
        json_path = os.path.join(output_path, f"{video_id}.json")
        with open(json_path, "w", encoding="utf-8") as jf:
            json.dump(json_output, jf, indent=2, ensure_ascii=False)
        
        print(f"üìù Metadata —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {video_id}.json")
        
        return True
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ {video_id}: {str(e)}")
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--video_path", type=str, required=True)
    parser.add_argument("--srt_path", type=str, default=None)
    parser.add_argument("--step", type=int, default=16, 
                      help="–®–∞–≥ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ (16 –æ–∑–Ω–∞—á–∞–µ—Ç –∫–∞–∂–¥—ã–π 16-–π –∫–∞–¥—Ä)")
    parser.add_argument("--output_path", type=str, default="output")
    
    args = parser.parse_args()
    slice_frames_pyav(args.video_path, args.srt_path, args.step, args.output_path)
